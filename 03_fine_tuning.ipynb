{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e4794c8-5472-462f-90da-9f0e8f77a494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This solution accelerator notebook is available at [Databricks Industry Solutions](https://github.com/databricks-industry-solutions/personalized_image_gen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d2d6e2-e747-4153-9691-e26e0dff3ccd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install requirements and load helper functions"
    }
   },
   "outputs": [],
   "source": [
    "%run ./99_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc730919-3610-40f9-b6dc-7dd3e35c826d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fine-tune Stable Diffusion XL with DreamBooth and LoRA\n",
    "For fine-tuning, we use [DreamBooth](https://dreambooth.github.io/), which is a technique to update the weights of a pre-trained text-to-image model using only a few images. We use the [Diffusers](https://huggingface.co/docs/diffusers/en/index)' implementation of DreamBooth in this solution accelerator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4cbe8bd-66d7-4a6e-aea1-3d0151342955",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set up TensorBoard\n",
    "[TensorBoard](https://www.tensorflow.org/tensorboard) is an open source monitoring solution for model training. It reads an event log and exposes the training metrics in near real-time on its dashboard, which helps gauge the status of fine-tuning without having to wait until it's done.\n",
    "\n",
    "Note that when you write the event log to DBFS, it won't show until the file is closed for writing, which is when the training is complete. This is not good for real time monitoring. So we suggest to write the event log out to the driver node and run your TensorBoard from there (see the cell below on how to do this). Files stored on the driver node may get removed when the cluster terminates or restarts. But when you are running the training on Databricks notebook, MLflow will automatically log your Tensorboard artifacts, and you will be able to recover them later. You can find the example of this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65d49ad4-6466-4376-a723-18697cbd8ef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorboard import notebook\n",
    "\n",
    "logdir = \"/databricks/driver/logdir/sdxl/\" # Write event log to the driver node\n",
    "notebook.start(\"--logdir {} --reload_multifile True\".format(logdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "076d6463-8637-402a-87af-bbb70065d56b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's specifiy some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f447229-5fdd-4ac3-ba22-8cddec893087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "theme = \"chair\"\n",
    "catalog = \"sdxl_image_gen\"\n",
    "volumes_dir = f\"/Volumes/{catalog}\"\n",
    "os.environ[\"DATASET_NAME\"] = f\"{volumes_dir}/{theme}/dataset\"\n",
    "os.environ[\"OUTPUT_DIR\"] = f\"{volumes_dir}/{theme}/adaptor\"\n",
    "os.environ[\"LOGDIR\"] = logdir\n",
    "\n",
    "# Make sure that the volume exists\n",
    "_ = spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog}.{theme}.adaptor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "945ac56a-de23-4d33-9880-4018459c365a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set Parameters\n",
    "To ensure we can use DreamBooth with LoRA on a heavy pipeline like Stable Diffusion XL, we use the following hyperparameters:\n",
    "\n",
    "* Gradient checkpointing (`--gradient_accumulation_steps`)\n",
    "* 8-bit Adam (`--use_8bit_adam`)\n",
    "* Mixed-precision training (`--mixed-precision=\"fp16\"`)\n",
    "* Some other parameters are defined in `yamls/zero2.yaml`\n",
    "<br>\n",
    "\n",
    "Other parameters:\n",
    "* Use `--output_dir` to specify your LoRA model repository name.\n",
    "* Use `--caption_column` to specify name of the caption column in your dataset.\n",
    "* Make sure to pass the right number of GPUs to the parameter `num_processes` in `yamls/zero2.yaml`: e.g. `num_processes` should be 8 for `g5.48xlarge`.\n",
    "<br>\n",
    "\n",
    "\n",
    "The following cell will run for about 15 minutes on a single node cluster with 8xA10GPU instances on the default training images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba5efaa-f8ce-4b6d-bc69-af789d9a30dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh accelerate launch --config_file yamls/zero2.yaml personalized_image_generation/train_dreambooth_lora_sdxl.py \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
    "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
    "  --dataset_name=$DATASET_NAME \\\n",
    "  --caption_column=\"caption\" \\\n",
    "  --instance_prompt=\"\" \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --resolution=1024 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=3 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --learning_rate=1e-4 \\\n",
    "  --snr_gamma=5.0 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --use_8bit_adam \\\n",
    "  --max_train_steps=500 \\\n",
    "  --checkpointing_steps=717 \\\n",
    "  --seed=\"0\" \\\n",
    "  --report_to=\"tensorboard\" \\\n",
    "  --logging_dir=$LOGDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edda62ee-5cec-41ef-9983-4f8924e8cb1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh ls -ltr $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96594c0e-bf54-4b11-9c90-8211dd8d4ad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test inference\n",
    "Lets take the fine-tuned model and generate some images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcef744b-ef1e-4d57-81aa-dbe79cfd38fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, AutoencoderKL\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    vae=vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    ")\n",
    "pipe.load_lora_weights(f\"{volumes_dir}/{theme}/adaptor/pytorch_lora_weights.safetensors\")\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f32e9f-9fe8-4fb4-95a8-1b4aad8da492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "types = os.listdir(\"./images/chair\")\n",
    "num_imgs_to_preview = len(types)\n",
    "imgs = []\n",
    "for type in types:\n",
    "    imgs.append(\n",
    "        pipe(\n",
    "            prompt=f\"A photo of a red {type} chair in a living room\",\n",
    "            num_inference_steps=25,\n",
    "        ).images[0]\n",
    "    )\n",
    "show_image_grid(imgs[:num_imgs_to_preview], 1, num_imgs_to_preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c7f7ea-bf74-4dfd-ac01-43f060ab4437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the model to MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf816ef-590b-4674-b29f-8e41b616702e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "\n",
    "class sdxl_fine_tuned(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, vae_name, model_name):\n",
    "        self.vae_name = vae_name\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def load_context(self, context):\n",
    "        \"\"\"\n",
    "        This method initializes the vae and the model\n",
    "        using the specified model repository.\n",
    "        \"\"\"\n",
    "        # Initialize tokenizer and language model\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.vae = diffusers.AutoencoderKL.from_pretrained(\n",
    "            self.vae_name, torch_dtype=torch.float16\n",
    "        )\n",
    "        self.pipe = diffusers.DiffusionPipeline.from_pretrained(\n",
    "            self.model_name,\n",
    "            vae=self.vae,\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True,\n",
    "        )\n",
    "        self.pipe.load_lora_weights(context.artifacts[\"repository\"])\n",
    "        self.pipe = self.pipe.to(self.device)\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        This method generates output for the given input.\n",
    "        \"\"\"\n",
    "        prompt = model_input[\"prompt\"][0]\n",
    "        num_inference_steps = model_input.get(\"num_inference_steps\", [25])[0]\n",
    "        # Generate the image\n",
    "        image = self.pipe(\n",
    "            prompt=prompt, num_inference_steps=num_inference_steps\n",
    "        ).images[0]\n",
    "        # Convert the image to numpy array for returning as prediction\n",
    "        image_np = np.array(image)\n",
    "        return image_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b14b7c4a-f611-487b-87c6-f267736ab6d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vae_name = \"madebyollin/sdxl-vae-fp16-fix\"\n",
    "model_name = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "output = f\"{volumes_dir}/{theme}/adaptor/pytorch_lora_weights.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a079cd0-c451-47c6-acee-af76fc2d8158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import DataType, Schema, ColSpec, TensorSpec\n",
    "import transformers, bitsandbytes, accelerate, deepspeed, diffusers\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Define input and output schema\n",
    "input_schema = Schema(\n",
    "    [ColSpec(DataType.string, \"prompt\"), ColSpec(DataType.long, \"num_inference_steps\")]\n",
    ")\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.uint8), (-1, 768, 3))])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "# Define input example\n",
    "input_example = pd.DataFrame(\n",
    "    {\"prompt\": [f\"A photo of a {theme} in a living room\"], \"num_inference_steps\": [25]}\n",
    ")\n",
    "\n",
    "# Log the model with its details such as artifacts, pip requirements and input example\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"model\",\n",
    "        python_model=sdxl_fine_tuned(vae_name, model_name),\n",
    "        artifacts={\"repository\": output},\n",
    "        pip_requirements=[\n",
    "            \"transformers==\" + transformers.__version__,\n",
    "            \"bitsandbytes==\" + bitsandbytes.__version__,\n",
    "            \"accelerate==\" + accelerate.__version__,\n",
    "            \"deepspeed==\" + deepspeed.__version__,\n",
    "            \"diffusers==\" + diffusers.__version__,\n",
    "            \"huggingface-hub==0.25.2\",\n",
    "        ],\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "    )\n",
    "    mlflow.set_tag(\"dataset\", f\"{volumes_dir}/{theme}/dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff93ba7c-8a94-4926-95b7-a0ba6903d6d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80725923-cbe2-4993-8709-ee9918ce894c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make sure that the schema for the model exist\n",
    "_ = spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.model\")\n",
    "\n",
    "# Register the model \n",
    "registered_name = f\"{catalog}.model.sdxl-fine-tuned-{theme}\"\n",
    "result = mlflow.register_model(\n",
    "    \"runs:/\" + run.info.run_id + \"/model\",\n",
    "    registered_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7679053d-e464-4926-bd7b-8cad3ab6acd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load the registered model back to make inference\n",
    "If you come accross an out of memory issue, restart the Python kernel to release the GPU memory occupied in Training. For this, uncomment and run the following cell, and re-define the variables such as ```theme```, ```catalog```, and ```volume_dir```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ca6e73c-8a15-4d86-b496-71ae410889b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78949b10-d4ed-4dc2-b26b-eaf8d0eaf9da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_latest_model_version(mlflow_client, registered_name):\n",
    "    latest_version = 1\n",
    "    for mv in mlflow_client.search_model_versions(f\"name='{registered_name}'\"):\n",
    "        version_int = int(mv.version)\n",
    "        if version_int > latest_version:\n",
    "            latest_version = version_int\n",
    "    return latest_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17b85615-1fa9-4b8b-9219-928e080d15bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import pandas as pd\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "registered_name = f\"{catalog}.model.sdxl-fine-tuned-{theme}\"\n",
    "model_version = get_latest_model_version(mlflow_client, registered_name)\n",
    "logged_model = f\"models:/{registered_name}/{model_version}\"\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "387524f3-9134-4a35-8ddb-1687089aa7dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Armed with this model, the design team can now explore new variations of their products and even produce all-together new items reflective of the designs of previously produced items in their portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2b59320-30b0-4bd0-90ef-72173e49b554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use any of the following token to generate personalized images: 'bcnchr', 'emslng', 'hsmnchr', 'rckchr', 'wdnchr'\n",
    "input_example = pd.DataFrame(\n",
    "    {\n",
    "        \"prompt\": [\"A photo of a long brown sofa in the style of the bcnchr chair\"],\n",
    "        \"num_inference_steps\": [25],\n",
    "    }\n",
    ")\n",
    "image = loaded_model.predict(input_example)\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc0949d0-bf40-4864-9215-56125b683303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assign an alias to the model\n",
    "mlflow_client.set_registered_model_alias(registered_name, \"champion\", model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b682dec9-4e7d-471d-b24a-030663eef98f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "© 2024 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the Databricks License. All included or referenced third party libraries are subject to the licenses set forth below.\n",
    "\n",
    "| library                                | description             | license    | source                                              |\n",
    "|----------------------------------------|-------------------------|------------|-----------------------------------------------------|\n",
    "| bitsandbytes | Accessible large language models via k-bit quantization for PyTorch. | MIT | https://pypi.org/project/bitsandbytes/\n",
    "| diffusers | A library for pretrained diffusion models for generating images, audio, etc. | Apache 2.0 | https://pypi.org/project/diffusers/\n",
    "| stable-diffusion-xl-base-1.0 | A model that can be used to generate and modify images based on text prompts. | CreativeML Open RAIL++-M License | https://github.com/Stability-AI/generative-models"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2038282820365438,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_fine_tuning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
